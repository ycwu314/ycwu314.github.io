---
title: 反爬虫系列之7：其他方案
date: 2019-09-03 18:26:47
tags: [爬虫, web]
categories: [爬虫]
keywords: [X-Frame-Option github pages]
description: 其他没有实施的方案，包括iframe、css content、生成pdf、不显示元素、css图片拼接等。
---

在实施站点反爬的过程，思考了一些方案，虽然这次没有实施，但也值得记录下来。

# iframe

不少爬虫程序处理iframe都比较弱鸡，尤其是嵌套的情况。因此最初考虑使用iframe嵌套方式保护页面内容。
思路是把正文放在另一个html，通过iframe加载。默认src=""，通过动态脚本加载替换src地址。
问题是工作量大，对hexo侵入太深。
另外嵌入iframe之后，比较丑，样式不好调。
<!-- more -->
# css content

CSS的content属性用于在元素的`::before`和`::after`伪元素中插入内容。
伪元素不会出现在dom结构，而是出现在css结构中。因为一般的页面解析是操作dom树，因此css content有很强的反爬能力。
可以使用python脚本先扫描正文，再抽取个别的字，用span占位符，把真实内容写入css content属性。
以后有需要可以实现。

# pdf

一般文章爬虫会忽略pdf资源。但是hexo有pdf插件，可以预览。可以考虑把代码块生成pdf文件再显示，实现保护代码正文。
但是实现成本高，需要在python脚本生成pdf文件，并且要带上语法颜色。
另一个问题是pdf文件体积大太多了。
因此不考虑。


# 不显示的随机元素

在文章中随机插入不可见的元素。文章爬虫做数据清理，通常会干掉css样式，结果这些隐藏元素显示出来，导致页面混乱。
以前投机取巧的SEO，会在页面里面塞入一堆关键字，并且不显示，搜索引擎傻傻的就把排名弄上去。
新版本的搜索引擎有识别页面不可显示元素的能力了。
有需要可以实现，不复杂。

# svg显示数字

把数字替换为svg文件，再显示。不过我已经实现了字体防爬，就没有必要了。

# css拼接图片和元素位移

通常用于数字敏感的内容，例如价格。具体参见：[爬虫笔记之自如房屋价格图片识别（价格字段css背景图片偏移显示）](https://www.cnblogs.com/cc11001100/p/10124741.html)。
不适合我的静态站点。

这里有一些例子，就不再重复实验：[反击爬虫，前端工程师的脑洞可以有多大？](https://imweb.io/topic/595b7161d6ca6b4f0ac71f05)。
